"""PYNQ-based driver for the DeepSoCFlow hardware accelerator.

This module provides a Python interface to the DeepSoCFlow CGRA
(Coarse-Grained Reconfigurable Array) accelerator, replacing the bare
metal C runtime with a PYNQ-based implementation for easier testing and
development.

The driver manages memory allocation, model configuration, and inference
execution, closely mimicking the behavior of the C runtime (runtime.h) to
ensure hardware compatibility.
"""

import pynq
import numpy as np
import json
import time

class DeepSoCFlowPYNQ:
    """PYNQ driver for DeepSoCFlow accelerator.

    This class provides a high-level interface to the DeepSoCFlow
    hardware accelerator, managing memory allocation, model setup, and
    inference execution. It replicates the behavior of the C runtime to
    ensure bit-accurate results.
    
    The driver handles:
        - Contiguous memory allocation matching the C Memory_st
          structure
        - Bundle parameter configuration and loading into accelerator
          BRAM
        - Synchronization between PS (Processing System) and PL
          (Programmable Logic)
        - Output post-processing including pooling, activation, and
          softmax
    
    Attributes:
        accelerator: PYNQ DefaultIP object for hardware access.
        mmio: Memory-mapped I/O interface to accelerator registers.
        defines: Hardware configuration parameters from config.json.
        bundles: List of layer/bundle configurations for the neural
            network.
        mem: Dictionary of memory buffers (ocm, weights, biases,
            input, output, etc.).
        mem_base: Base contiguous memory buffer allocated for the
            accelerator.
        physical_addresses: Dictionary mapping buffer names to their
            physical addresses.
    """

    def __init__(self, overlay: pynq.Overlay, config_path: str,
                 accelerator_ip_name: str):
        """Initialize the DeepSoCFlow PYNQ driver.

        Args:
            overlay: PYNQ overlay containing the accelerator IP.
            config_path: Path to the hardware configuration JSON file
                (config.json). This file is generated by xmodel.py's
                export_inference() function and contains hardware
                parameters and bundle configurations.
            accelerator_ip_name: Name of the accelerator IP block in
                the overlay.

        Raises:
            AttributeError: If the accelerator IP is not found in the
                overlay.
        """
        if accelerator_ip_name not in overlay.ip_dict:
            raise AttributeError(
                f"Could not find IP '{accelerator_ip_name}' in "
                f"overlay.ip_dict. Available IPs are: "
                f"{list(overlay.ip_dict.keys())}"
            )
        
        ip_description = overlay.ip_dict[accelerator_ip_name]
        self.accelerator = pynq.overlay.DefaultIP(
            description=ip_description)
        self.mmio = self.accelerator.mmio

        print(f"\n--- Accelerator '{accelerator_ip_name}' "
              f"Hardware Info ---")
        phys_addr = ip_description['phys_addr']
        addr_range = ip_description['addr_range']
        print(f"  > Physical Address Range: 0x{phys_addr:08x} - "
              f"0x{phys_addr + addr_range - 1:08x}")
        print(f"  > Address Range Size: {addr_range} bytes")
        print(f"--------------------------------------------------")

        print(f"\nLoading configuration from {config_path}...")
        with open(config_path, 'r') as f:
            config = json.load(f)
        
        self.defines = config['defines']
        self.bundles = config['bundles']

        self.mem = {}

        # Mapping from string type names to NumPy dtypes
        self._str_to_dtype = {
            'int8': np.int8, 'int16': np.int16, 'int32': np.int32,
            'int64': np.int64, 'uint8': np.uint8, 'uint16': np.uint16,
            'uint32': np.uint32, 'uint64': np.uint64,
            'float32': np.float32, 'float64': np.float64
        }
        
        # Hardware register offsets matching the C runtime definitions
        self.REG_OFFSETS = {
            'A_START'       : 0x0,
            'A_DONE_READ'   : 0x1,
            'A_DONE_WRITE'  : 0x3,
            'A_OCM_BASE'    : 0x5,
            'A_WEIGHTS_BASE': 0x7,
            'A_BUNDLE_DONE' : 0x8,
            'A_N_BUNDLES_1' : 0x9,
            'A_W_DONE'      : 0xA,
            'A_X_DONE'      : 0xB,
            'A_O_DONE'      : 0xC,
            'A_PARAMS_BASE' : 16,
        }

        self._allocate_memory()

    def _allocate_memory(self):
        """Allocate memory buffers matching C runtime Memory_st struct.

        This method creates a single contiguous memory buffer and sets
        up views for:
            - OCM banks (2 banks)
            - NHWC buffer (intermediate output storage)
            - Output buffers (for layer outputs)
            - Weights, biases, and input data
            - Residual add buffers (if needed)

        The memory layout exactly matches the C runtime to ensure
        compatibility. Physical addresses are stored separately for
        hardware register configuration.
        """
        print("Allocating memory buffers...")
        defs = self.defines

        # Retrieve data types from configuration
        y_type = self._str_to_dtype[defs['Y_TYPE_str']]
        b_type = self._str_to_dtype[defs['B_TYPE_str']]
        o_type = self._str_to_dtype[defs['O_TYPE_str']]

        # Calculate sizes in bytes for each memory component
        ocm_size = (2 * defs['PE_COLS'] * defs['PE_ROWS'] *
                    np.dtype(y_type).itemsize)
        nhwc_size = defs['NHWC_WORDS'] * 4  # int32
        out_buffers_size = (defs['N_OUT_BUF'] *
                            defs['O_BYTES_MAX'])
        w_size = defs['W_BYTES']
        b_size = defs['B_WORDS'] * np.dtype(b_type).itemsize
        x_size = defs['X_BYTES']
        y_size = defs['O_WORDS'] * np.dtype(o_type).itemsize
        add_buffers_size = (defs['N_ADD_BUF'] * defs['NHWC_WORDS']
                            if defs['N_ADD_BUF'] > 0 else 0)
        
        # Calculate total size and align to 4KB boundary
        total_size = (ocm_size + nhwc_size + out_buffers_size +
                    w_size + b_size + x_size + y_size + add_buffers_size)
        total_size = ((total_size + 4095) // 4096) * 4096

        print(f"Allocating single contiguous buffer of "
              f"{total_size} bytes...")

        # Allocate one large contiguous buffer as uint8 for byte-level
        # access
        self.mem_base = pynq.allocate(shape=(total_size,),
                                      dtype=np.uint8, cacheable=True)

        print(f"Memory base physical address: "
              f"0x{self.mem_base.physical_address:08x}")
        
        self.physical_addresses = {}

        # Create views into the buffer at the correct offsets
        # (matching C struct layout)
        offset = 0

        # OCM banks:
        # [2][PE_COLS*PE_ROWS]
        ocm_elements_per_bank = defs['PE_COLS'] * defs['PE_ROWS']
        self.mem['ocm'] = []
        for i in range(2):
            ocm_view = self.mem_base[
                offset:offset + ocm_elements_per_bank *
                np.dtype(y_type).itemsize]
            self.mem['ocm'].append(
                ocm_view.view(dtype=y_type).reshape(
                    ocm_elements_per_bank))
            phys_addr_key = f'ocm_{i}'
            self.physical_addresses[phys_addr_key] = (
                self.mem_base.physical_address + offset)
            offset += ocm_elements_per_bank * np.dtype(y_type).itemsize
            print(f"OCM Bank {i} physical address: "
                  f"0x{self.physical_addresses[phys_addr_key]:08x}")
        
        # NHWC buffer [NHWC_WORDS] - int32
        nhwc_view = self.mem_base[offset:offset + defs['NHWC_WORDS'] * 4]
        self.mem['nhwc'] = nhwc_view.view(dtype=np.int32).reshape(
            defs['NHWC_WORDS'])
        self.physical_addresses['nhwc'] = (
            self.mem_base.physical_address + offset)
        offset += defs['NHWC_WORDS'] * 4

        # Out buffers [N_OUT_BUF][O_BYTES_MAX] - int8
        out_buffers_view = self.mem_base[
            offset:offset + defs['N_OUT_BUF'] * defs['O_BYTES_MAX']]
        self.mem['out_buffers'] = (
            out_buffers_view.view(dtype=np.int8).reshape(
                defs['N_OUT_BUF'], defs['O_BYTES_MAX']))
        self.physical_addresses['out_buffers'] = (
            self.mem_base.physical_address + offset)
        offset += defs['N_OUT_BUF'] * defs['O_BYTES_MAX']

        # Weights [W_BYTES] - int8
        w_view = self.mem_base[offset:offset + defs['W_BYTES']]
        self.mem['w'] = w_view.view(dtype=np.int8).reshape(
            defs['W_BYTES'])
        self.physical_addresses['w'] = (
            self.mem_base.physical_address + offset)
        offset += defs['W_BYTES']

        # Biases [B_WORDS] - B_TYPE
        b_view = self.mem_base[
            offset:offset + defs['B_WORDS'] *
            np.dtype(b_type).itemsize]
        self.mem['b'] = b_view.view(dtype=b_type).reshape(
            defs['B_WORDS'])
        self.physical_addresses['b'] = (
            self.mem_base.physical_address + offset)
        offset += defs['B_WORDS'] * np.dtype(b_type).itemsize

        # Input [X_BYTES] - int8
        x_view = self.mem_base[offset:offset + defs['X_BYTES']]
        self.mem['x'] = x_view.view(dtype=np.int8).reshape(
            defs['X_BYTES'])
        self.physical_addresses['x'] = (
            self.mem_base.physical_address + offset)
        offset += defs['X_BYTES']

        # Output [O_WORDS] - O_TYPE
        y_view = self.mem_base[
            offset:offset + defs['O_WORDS'] *
            np.dtype(o_type).itemsize]
        self.mem['y'] = y_view.view(dtype=o_type).reshape(
            defs['O_WORDS'])
        self.physical_addresses['y'] = (
            self.mem_base.physical_address + offset)
        offset += defs['O_WORDS'] * np.dtype(o_type).itemsize

        # Add buffers (if any)
        if defs['N_ADD_BUF'] > 0:
            add_buffers_view = self.mem_base[
                offset:offset + defs['N_ADD_BUF'] *
                defs['NHWC_WORDS']]
            self.mem['add_buffers'] = (
                add_buffers_view.view(dtype=np.int8).reshape(
                    defs['N_ADD_BUF'], defs['NHWC_WORDS']))
            self.physical_addresses['add_buffers'] = (
                self.mem_base.physical_address + offset)
            offset += defs['N_ADD_BUF'] * defs['NHWC_WORDS']

        # Allocate parameters buffer separately (this goes to BRAM,
        # not main memory)
        self.mem['params'] = pynq.allocate(
            shape=(defs['N_BUNDLES'], 8), dtype=np.uint32,
            cacheable=True)
        
        print("Memory allocation complete.")

    def model_setup(self, wbx_path: str):
        """Load model data and configure accelerator hardware.

        This method loads weights, biases, and input data from a binary
        file (wbx.bin), then pre-loads all bundle parameters into the
        accelerator's BRAM and configures the hardware registers.

        Args:
            wbx_path: Path to the binary file containing weights,
                biases, and input data.
        """
        print(f"\nSetting up model from {wbx_path}...")

        w_bytes = self.mem['w'].nbytes
        b_bytes = self.mem['b'].nbytes

        with open(wbx_path, 'rb') as f:
            wbx_data = f.read()

        np.copyto(self.mem['w'],
                  np.frombuffer(wbx_data[:w_bytes],
                                dtype=self.mem['w'].dtype))
        np.copyto(self.mem['b'],
                  np.frombuffer(wbx_data[w_bytes : w_bytes + b_bytes],
                                dtype=self.mem['b'].dtype))
        np.copyto(self.mem['x'],
                  np.frombuffer(wbx_data[w_bytes + b_bytes:],
                                dtype=self.mem['x'].dtype))
        
        self.mem_base.flush()
        print("\nData copy complete.")

        print("Pre-loading all bundle parameters into accelerator "
              "BRAM...")

        params_buf = self.mem['params']

        for ib, b in enumerate(self.bundles):
            # Determine input buffer address (either initial input or
            # intermediate buffer)
            if b['in_buffer_idx'] == -1:
                x_addr = self.physical_addresses['x']
            else:
                x_addr = (self.physical_addresses['out_buffers'] +
                          b['in_buffer_idx'] *
                          self.defines['O_BYTES_MAX'])

            # Pack bundle parameters matching the C runtime structure
            params_buf[ib][0] = x_addr
            params_buf[ib][1] = b['x_bpt_p0']
            params_buf[ib][2] = b['x_bpt']
            params_buf[ib][3] = b['w_bpt_p0']
            params_buf[ib][4] = b['w_bpt']
            params_buf[ib][5] = (b['t'] << 16) + b['p']

            header = b['header']
            params_buf[ib][6] = header & 0xFFFFFFFF
            params_buf[ib][7] = header >> 32

        # Write parameters into accelerator's BRAM via MMIO
        params_flat = params_buf.flatten()
        for i, val in enumerate(params_flat):
            self.mmio.write(
                (self.REG_OFFSETS['A_PARAMS_BASE'] + i) * 4, int(val))

        params_buf.flush()
        print("Parameter loading complete.")

        # Configure hardware registers with physical memory addresses
        # and control signals
        self.mmio.write(self.REG_OFFSETS['A_START'] * 4, 0)
        self.mmio.write((self.REG_OFFSETS['A_DONE_READ'] + 0) * 4, 1)
        self.mmio.write((self.REG_OFFSETS['A_DONE_READ'] + 1) * 4, 1)
        self.mmio.write((self.REG_OFFSETS['A_DONE_WRITE'] + 0) * 4, 0)
        self.mmio.write((self.REG_OFFSETS['A_DONE_WRITE'] + 1) * 4, 0)
        self.mmio.write(
            (self.REG_OFFSETS['A_OCM_BASE'] + 0) * 4,
            self.physical_addresses['ocm_0'])
        self.mmio.write(
            (self.REG_OFFSETS['A_OCM_BASE'] + 1) * 4,
            self.physical_addresses['ocm_1'])
        self.mmio.write(self.REG_OFFSETS['A_WEIGHTS_BASE'] * 4,
                        self.physical_addresses['w'])
        self.mmio.write(self.REG_OFFSETS['A_BUNDLE_DONE'] * 4, 1)
        self.mmio.write(self.REG_OFFSETS['A_N_BUNDLES_1'] * 4,
                        self.defines['N_BUNDLES'])
        self.mmio.write(self.REG_OFFSETS['A_W_DONE'] * 4, 0)
        self.mmio.write(self.REG_OFFSETS['A_X_DONE'] * 4, 0)
        self.mmio.write(self.REG_OFFSETS['A_O_DONE'] * 4, 0)

        print("Register configuration complete.")
        print(f"OCM Bank 0 address: "
              f"0x{self.physical_addresses['ocm_0']:08x}")
        print(f"OCM Bank 1 address: "
              f"0x{self.physical_addresses['ocm_1']:08x}")
        print(f"Weights address: 0x{self.physical_addresses['w']:08x}")
        print("Model setup finished.")


    def model_run(self):
        """Execute model inference on the accelerator.

        This method orchestrates the complete inference process,
        including:
            - Starting the hardware accelerator
            - Processing bundles sequentially
            - Managing double-buffered OCM banks for PS-PL
              synchronization
            - Applying post-processing (bias, activation, pooling,
              softmax)
            - Handling residual connections and tiling for intermediate
              layers

        Returns:
            np.ndarray: Final network output (either float32 for
                softmax or int32).
        """
        print("\n--- Starting Model Inference ---")
        start_time = time.time()

        self.mmio.write(self.REG_OFFSETS['A_START'] * 4, 1)

        ocm_bank = 1

        for ib, b in enumerate(self.bundles):
            nhwc_buf_shape = (b['n'], b['ch'], b['cw'], b['co'])
            nhwc_buf_size = np.prod(nhwc_buf_shape)
            nhwc_buf = np.zeros(nhwc_buf_size, dtype=np.int32)

            is_last_bundle = (ib == len(self.bundles) - 1)
            if is_last_bundle:
                p_out_buffer = self.mem['y']
            else:
                p_out_buffer = (
                    self.mem['out_buffers'][b['out_buffer_idx']])

            if ib < len(self.bundles) - 1:
                p_out_buffer.fill(0)

            for ip in range(b['p']):
                for it in range(b['t']):
                    it_bias = b['b_offset'] + b['coe'] * it

                    for in_ in range(b['n']):
                        for il in range(b['l']):
                            for iw_kw2 in range(b['w_kw2']):
                                ocm_bank = 1 - ocm_bank
                                w_last = (b['kw'] // 2 + 1
                                          if iw_kw2 == b['w_kw2'] - 1
                                          else 1)

                                # Wait for accelerator to finish writing
                                # to OCM
                                while not self.mmio.read(
                                    (self.REG_OFFSETS['A_DONE_WRITE'] +
                                     ocm_bank) * 4):
                                    pass

                                # Ensure cache coherency by invalidating
                                # the buffer
                                self.mem_base.sync_from_device()
                                self.mmio.write(
                                    (self.REG_OFFSETS['A_DONE_WRITE'] +
                                     ocm_bank) * 4, 0)

                                # Process OCM data on PS side
                                sram_addr = 0
                                for icoe in range(b['coe']):
                                    i_bias = it_bias + icoe
                                    for iw_last in range(w_last):
                                        for ir in range(
                                                self.defines['PE_ROWS']):
                                            i_yn = in_
                                            i_yh = (il *
                                                    self.defines['PE_ROWS']
                                                    + ir)
                                            i_yw = iw_kw2 + iw_last
                                            i_yc = b['coe'] * it + icoe

                                            yn = b['n']
                                            yh = b['h']
                                            yw = b['w']
                                            yc = b['co']

                                            if i_yh >= yh or i_yc >= yc:
                                                sram_addr += 1
                                                continue

                                            raw_val = (
                                                self.mem['ocm']
                                                [ocm_bank][sram_addr])
                                            out_val = np.int32(raw_val)
                                            sram_addr += 1

                                            iy_nhwc = (
                                                self._flatten_nhwc(
                                                    i_yn, i_yh, i_yw, i_yc,
                                                    yn, yh, yw, yc))

                                            # Handle multi-pass accumulation
                                            # (for large channels split
                                            # across P passes)
                                            if b['p'] == 1:
                                                pass
                                            elif ip == b['p'] - 1:
                                                out_val += (
                                                    self.mem['nhwc']
                                                    [iy_nhwc])
                                            elif ip == 0:
                                                (self.mem['nhwc']
                                                 [iy_nhwc]) = out_val
                                                continue
                                            else:
                                                (self.mem['nhwc']
                                                 [iy_nhwc]) += out_val
                                                continue

                                            # Apply convolution striding
                                            csh_check = (
                                                (i_yh - b['csh_shift']) %
                                                b['csh'] != 0)
                                            csw_check = (
                                                (i_yw - b['csw_shift']) %
                                                b['csw'] != 0)
                                            if csh_check or csw_check:
                                                continue

                                            i_yh = ((i_yh -
                                                    b['csh_shift']) //
                                                   b['csh'])
                                            i_yw = ((i_yw -
                                                    b['csw_shift']) //
                                                   b['csw'])
                                            yh = b['ch']
                                            yw = b['cw']
                                            # Add bias
                                            if b.get('is_bias', False):
                                                bias = np.int16(
                                                    self.mem['b'][i_bias])
                                                out_val = (
                                                    (np.int32(out_val) <<
                                                     b['b_val_shift']) +
                                                    (np.int32(bias) <<
                                                     b['b_bias_shift']))

                                            # Apply core activation
                                            # (quantized LeakyReLU)
                                            out_val = self._quant_lrelu(
                                                out_val, b['ca_nzero'],
                                                b['ca_shift'],
                                                b['ca_pl_scale'])

                                            # Handle residual addition
                                            if (b.get('add_in_buffer_idx', -1)
                                                    != -1):
                                                add_iy_nhwc = (
                                                    self._flatten_nhwc(
                                                        i_yn, i_yh, i_yw,
                                                        i_yc, b['n'],
                                                        b['ch'], b['cw'],
                                                        b['co']))
                                                add_val = int(
                                                    self.mem['add_buffers']
                                                    [b['add_in_buffer_idx']]
                                                    [add_iy_nhwc])
                                                out_val = (
                                                    np.int32(out_val) +
                                                    np.int32(add_val))
                                                out_val = (
                                                    self._quant_lrelu(
                                                        out_val,
                                                        b['aa_nzero'],
                                                        b['aa_shift'],
                                                        b['aa_pl_scale']))

                                            # Handle softmax output layer
                                            if b.get('is_softmax', False):
                                                self._handle_softmax(
                                                    b, ib, out_val, i_yn,
                                                    i_yh, i_yw, i_yc, yn,
                                                    yh, yw, yc)
                                                continue

                                            # Handle pooling (max or avg)
                                            if b['pool'] != 'POOL_NONE':
                                                pool_result = (
                                                    self._handle_pooling(
                                                        b, out_val,
                                                        p_out_buffer,
                                                        nhwc_buf, i_yn,
                                                        i_yh, i_yw, i_yc,
                                                        yn, yh, yw, yc))
                                                if pool_result is None:
                                                    continue

                                                yh, yw = pool_result
                                                continue

                                            # Write output (tile format for
                                            # intermediate layers, NHWC
                                            # for final)
                                            is_last_bundle = (ib ==
                                                             len(self.bundles
                                                                 ) - 1)

                                            if is_last_bundle:
                                                final_iy_nhwc = (
                                                    self._flatten_nhwc(
                                                        i_yn, i_yh, i_yw,
                                                        i_yc, b['n'],
                                                        b['ch'], b['cw'],
                                                        b['co']))
                                                if final_iy_nhwc < (
                                                        nhwc_buf.size):
                                                    nhwc_buf[
                                                        final_iy_nhwc
                                                    ] = out_val
                                            else:
                                                self._tile_write(
                                                    out_val, p_out_buffer,
                                                    b, i_yn, i_yh, i_yw,
                                                    i_yc, yn, yh, yw, yc)

                                            # Store for residual
                                            # connections if needed
                                            if (b.get(
                                                'add_out_buffer_idx', -1)
                                                    != -1):
                                                final_iy_nhwc = (
                                                    self._flatten_nhwc(
                                                        i_yn, i_yh, i_yw,
                                                        i_yc, b['n'],
                                                        b['ch'], b['cw'],
                                                        b['co']))
                                                add_buf_idx = (
                                                    b['add_out_buffer_idx'])
                                                if final_iy_nhwc < (
                                                    self.mem['add_buffers']
                                                    [add_buf_idx].size):
                                                    self.mem[
                                                        'add_buffers'
                                                    ][add_buf_idx][
                                                        final_iy_nhwc
                                                    ] = np.int8(out_val)

                                # Signal PS has finished reading OCM bank
                                self.mmio.write(
                                    (self.REG_OFFSETS['A_DONE_READ'] +
                                     ocm_bank) * 4, 1)

            # Signal bundle processing complete
            self.mem_base.flush()
            self.mmio.write(self.REG_OFFSETS['A_BUNDLE_DONE'] * 4, 1)

        end_time = time.time()
        print(f"\n--- Model Inference Finished in "
              f"{end_time - start_time:.4f} seconds ---")

        # Return the correct final output buffer
        if self.bundles[-1].get('is_softmax', False):
            return self.mem['y']
        return nhwc_buf

    def _tile_write(self, out_val, p_out_buffer, pb, i_yn, i_yh, i_yw,
                    i_yc, yn, yh, yw, yc):
        """Write output value to tiled buffer format for next layer.

        This method converts NHWC output into the tiled format expected
        by the next layer, handling flattening, padding, and sweeping
        operations to match the C runtime behavior.

        Args:
            out_val: Output value to write.
            p_out_buffer: Output buffer to write to.
            pb: Current bundle configuration.
            i_yn, i_yh, i_yw, i_yc: Output tensor indices
                (N, H, W, C).
            yn, yh, yw, yc: Output tensor dimensions.
        """
        # Flatten tensor dimensions if this is a flatten layer
        if pb.get('is_flatten', False):
            i_yc = (i_yh * yw + i_yw) * yc + i_yc
            i_yw = 0
            i_yh = i_yn
            i_yn = 0

            yc = yh * yw * yc
            yw = 1
            yh = yn
            yn = 1

        # Store for residual add if needed
        if pb.get('add_out_buffer_idx', -1) != -1:
            iy_nhwc = self._flatten_nhwc(i_yn, i_yh, i_yw, i_yc,
                                         pb['on'], pb['oh'], pb['ow'],
                                         pb['oc'])
            add_buf_idx = pb['add_out_buffer_idx']
            if iy_nhwc < self.mem['add_buffers'][add_buf_idx].size:
                self.mem['add_buffers'][add_buf_idx][iy_nhwc] = (
                    np.int8(out_val))

        if pb.get('ib_out', -1) == -1:
            return

        pb_out = self.bundles[pb['ib_out']]

        # Calculate tiling coordinates
        yp_first = i_yc < pb_out['cm_p0']
        i_yr = i_yh % self.defines['PE_ROWS']
        i_yl = i_yh // self.defines['PE_ROWS']

        if yp_first:
            i_yp, i_ycm, ycm = 0, i_yc, pb_out['cm_p0']
        else:
            i_yp = ((i_yc - pb_out['cm_p0']) //
                    pb_out['cm'] + 1)
            i_ycm = ((i_yc - pb_out['cm_p0']) %
                     pb_out['cm'])
            ycm = pb_out['cm']

        # Sweep to fill PE row, padding as needed
        yr_sweep = (self.defines['PE_ROWS']
                    if i_yh == yh - 1 else i_yr + 1)
        original_out_val = out_val

        for i_yr_dest in range(i_yr, yr_sweep):
            self._write_x(out_val, p_out_buffer, i_yp, i_yn, i_yl,
                         i_yw, i_ycm, i_yr_dest, pb_out, ycm)

            # Add padding between blocks if needed
            if i_yr_dest < pb_out['x_pad']:
                pad_val = 0 if i_yl == 0 else original_out_val
                dest_yl = (pb_out['l'] - 1
                          if i_yl == 0 else i_yl - 1)
                self._write_x(pad_val, p_out_buffer, i_yp, i_yn,
                             dest_yl, i_yw, i_ycm,
                             i_yr_dest + self.defines['PE_ROWS'],
                             pb_out, ycm)

            out_val = 0
            
    def _write_x(self, val, p_out_buffer, ixp, ixn, ixl, ixw, ixcm,
                 ixr, pb_out, xcm):
        """Pack and write a value into tiled output buffer.

        Matches the C runtime write_x function for bit-packing values
        into the tiled format at the correct offset and bit position.

        Args:
            val: Value to write.
            p_out_buffer: Output buffer to write to.
            ixp, ixn, ixl, ixw, ixcm, ixr: Tiling coordinates.
            pb_out: Next bundle configuration.
            xcm: Channel multiplier for current pass.
        """
        if ixp == 0:
            p_offset = 0
        else:
            p_offset = ((pb_out['cm_p0'] + (ixp - 1) *
                         pb_out['cm']) * pb_out['xp_words'])
        pe_rows_padded = (self.defines['PE_ROWS'] +
                          pb_out['x_pad'])
        flat_index = (p_offset +
                      (((ixn * pb_out['l'] + ixl) *
                        pb_out['w'] + ixw) * xcm + ixcm) *
                      pe_rows_padded + ixr)

        x_bits = 1 << self.defines['X_BITS_L2']
        x_words_per_byte = 8 // x_bits

        if x_words_per_byte == 0:
            return

        byte_idx = flat_index // x_words_per_byte
        bit_offset = (flat_index % x_words_per_byte) * x_bits

        if byte_idx < p_out_buffer.size:
            mask = (1 << x_bits) - 1
            existing_byte = p_out_buffer[byte_idx]
            clear_mask = ~(mask << bit_offset)
            new_byte = ((existing_byte & clear_mask) |
                       ((int(val) & mask) << bit_offset))
            p_out_buffer[byte_idx] = new_byte

    def _handle_softmax(self, b, ib, out_val, i_yn, i_yh, i_yw, i_yc,
                        yn, yh, yw, yc):
        """Apply softmax activation to output layer.

        De-quantizes the output value, applies exponential function, and
        normalizes across all channels for each spatial location.

        Args:
            b: Current bundle configuration.
            ib: Bundle index (must be last bundle).
            out_val: Quantized output value.
            i_yn, i_yh, i_yw, i_yc: Output tensor indices.
            yn, yh, yw, yc: Output tensor dimensions.
        """
        assert (ib == len(self.bundles) - 1),\
            "Softmax is only allowed for the last bundle."

        val = float(out_val)
        val /= (1 << b['softmax_frac'])
        val -= b['softmax_max_f']
        val = np.exp(val)

        iy_nhwc = self._flatten_nhwc(i_yn, i_yh, i_yw, i_yc, yn, yh,
                                     yw, yc)
        self.mem['y'][iy_nhwc] = val

        # Normalize across channels when last channel is processed
        if i_yc == b['co'] - 1:
            sum_exp = 0.0
            for i in range(b['co']):
                iy_nhwc_sum = self._flatten_nhwc(
                    i_yn, i_yh, i_yw, i, yn, yh, yw, yc)
                sum_exp += self.mem['y'][iy_nhwc_sum]

            if sum_exp != 0:
                for i in range(b['co']):
                    iy_nhwc_norm = self._flatten_nhwc(
                        i_yn, i_yh, i_yw, i, yn, yh, yw, yc)
                    self.mem['y'][iy_nhwc_norm] /= sum_exp
    
    def _handle_pooling(self, b, out_val, p_out_buffer, nhwc_buf, i_yn,
                        i_yh, i_yw, i_yc, yn, yh, yw, yc):
        """Apply max or average pooling operation.

        Stores values in NHWC buffer and computes pooled outputs when
        windows are complete. Handles both max and average pooling with
        proper activation.

        Args:
            b: Current bundle configuration.
            out_val: Output value to pool.
            p_out_buffer: Output buffer for pooled results.
            nhwc_buf: Temporary NHWC buffer for storing pre-pooled
                values.
            i_yn, i_yh, i_yw, i_yc: Output tensor indices.
            yn, yh, yw, yc: Output tensor dimensions.

        Returns:
            Tuple of (pooled_height, pooled_width) or None if pooling
            window incomplete.
        """
        iy_nhwc = self._flatten_nhwc(i_yn, i_yh, i_yw, i_yc, yn, yh,
                                     yw, yc)
        nhwc_buf[iy_nhwc] = out_val

        # Calculate output pooling grid coordinates
        ixh_beg, rem_ixh = divmod(
            i_yh + b['psh_shift'] - b['pkh'] + 1, b['psh'])
        ixw_beg, rem_ixw = divmod(
            i_yw + b['psw_shift'] - b['pkw'] + 1, b['psw'])

        if ixh_beg < 0 or ixw_beg < 0:
            return None

        # Check if pooling window is ready to compute
        if rem_ixh != 0:
            if i_yh == yh - 1:
                ixh_beg += 1
            else:
                return None
        if rem_ixw != 0:
            if i_yw == yw - 1:
                ixw_beg += 1
            else:
                return None

        # Define pooling window boundaries
        ph_end = i_yh
        pw_end = i_yw
        ph_beg_const = (max(b['psh'] * ixh_beg - b['psh_shift'], 0)
                        - 1)
        pw_beg_const = (max(b['psw'] * ixw_beg - b['psw_shift'], 0)
                        - 1)

        xh_sweep = b['oh'] if i_yh == yh - 1 else ixh_beg + 1
        xw_sweep = b['ow'] if i_yw == yw - 1 else ixw_beg + 1

        # Compute pooled values across the window
        _ph_beg = ph_beg_const
        for ixh in range(ixh_beg, xh_sweep):
            _pw_beg = pw_beg_const
            for ixw in range(ixw_beg, xw_sweep):
                if b['pool'] == 'POOL_MAX':
                    result = -2147483648
                else:
                    result = 0
                count = 0
                for ipyh in range(_ph_beg + 1, ph_end + 1):
                    for ipyw in range(_pw_beg + 1, pw_end + 1):
                        read_idx = self._flatten_nhwc(
                            i_yn, ipyh, ipyw, i_yc, yn, yh, yw, yc)
                        read_val = nhwc_buf[read_idx]
                        if b['pool'] == 'POOL_MAX':
                            result = max(result, read_val)
                        else:
                            result = result + read_val
                        count += 1

                if b['pool'] == 'POOL_AVG':
                    result = (self.div_round(result, count)
                              if count > 0 else 0)
                    result = self._quant_lrelu(
                        result, b['pa_nzero'], b['pa_shift'],
                        b['pa_pl_scale'])

                self._tile_write(result, p_out_buffer, b, i_yn, ixh,
                                ixw, i_yc, yn, b['ph'], b['pw'], yc)

                _pw_beg += b['psw']
            _ph_beg += b['psh']

        return b['ph'], b['pw']

    def _flatten_nhwc(self, in_val, ih, iw, ic, N, H, W, C):
        """Flatten NHWC tensor coordinates to linear index.
        
        Args:
            in_val: Batch index (N).
            ih: Height index (H).
            iw: Width index (W).
            ic: Channel index (C).
            N, H, W, C: Tensor dimensions.
            
        Returns:
            Linear index into flattened NHWC array.
        """
        return ((in_val * H + ih) * W + iw) * C + ic

    def _quant_lrelu(self, x, nzero, shift, pl_scale):
        """Apply quantized Leaky ReLU activation.

        Implements the quantized activation function matching the C
        runtime behavior, including leaky ReLU, bit shifting, and range
        clipping.

        Args:
            x: Input value.
            nzero: Enable leaky behavior (1) or standard ReLU (0).
            shift: Right shift amount for quantization.
            pl_scale: Left shift for positive values (piecewise linear
                scale).

        Returns:
            Quantized and clipped activation output.
        """
        x_bits = 1 << self.defines['X_BITS_L2']

        # Apply Leaky ReLU: pass negative values if nzero, else zero
        # them
        if x < 0:
            leaky_x = x if nzero else 0
        else:
            leaky_x = x << pl_scale

        shifted_x = self.shift_round(leaky_x, shift)

        # Clip to valid quantization range
        min_val = -(1 << (x_bits - pl_scale - 1))
        max_val = (1 << (x_bits - 1)) - 1
        clipped_x = np.clip(shifted_x, min_val, max_val)

        return clipped_x

    def shift_round(self, n, s):
        """Perform right shift with round-half-to-even rounding.

        Matches the C runtime shift_round macro exactly using 32-bit
        signed integer arithmetic.

        Args:
            n: Value to shift.
            s: Shift amount (bits).

        Returns:
            Rounded and shifted result.
        """
        if s <= 0:
            return n

        n = np.int32(n)
        s = np.int32(s)

        n_shifted = np.int32(n >> s)
        correction = np.int32((~n_shifted) & 1)
        term = np.int32((1 << (s - 1)) - correction)
        return np.int32((n + term) >> s)

    def div_round(self, a, b):
        """Perform integer division with round-half-to-even rounding.

        Implements the C runtime div_round macro using 32-bit signed
        integer arithmetic.

        Args:
            a: Numerator.
            b: Denominator.

        Returns:
            Rounded division result.

        Raises:
            ZeroDivisionError: If b is zero.
        """
        if b == 0:
            raise ZeroDivisionError("Division by zero")

        a = np.int32(a)
        b = np.int32(b)

        quotient = np.int32(a // b)
        b_or_quotient = np.int32(b | quotient)
        not_b_or_quotient = np.int32(~b_or_quotient)
        correction = not_b_or_quotient & 1
        numerator = a + (b // 2) - correction

        return np.int32(numerator // b)

    def __del__(self):
        """Release allocated memory buffers on cleanup."""
        print("\nReleasing memory buffers.")
        if hasattr(self, 'mem_base') and self.mem_base is not None:
            self.mem_base.freebuffer()

        params_buf = self.mem.get('params')
        if params_buf is not None and hasattr(params_buf,
                                              'freebuffer'):
            params_buf.freebuffer()